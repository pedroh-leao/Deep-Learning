{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network To Classify Handwritten Digits\n",
    "\n",
    "Using the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Dense, Dropout, Conv2D, MaxPooling2D, Flatten, BatchNormalization\n",
    "from tensorflow.keras import utils as np_utils\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.max(), x_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Class 5')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0], cmap= 'gray')\n",
    "plt.title('Class ' + str(y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pre-processing the data to send it to the neural network\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1) # if it was a colored image, the last parameter would be 3 (rgb)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "\n",
    "# normalizing the data\n",
    "x_train /= 255\n",
    "x_train.max(), x_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# normalizing the data\n",
    "x_test /= 255\n",
    "x_test.max(), x_test.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class -> one-hot representation\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a more complex neural network than necessary for study purposes\n",
    "model = Sequential()\n",
    "\n",
    "model.add(InputLayer(shape= (28, 28, 1)))\n",
    "\n",
    "model.add(Conv2D(filters= 32, kernel_size= (3, 3), activation= 'relu')) #  convolution layer\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size= (2, 2))) # pooling layer\n",
    "\n",
    "model.add(Conv2D(filters= 32, kernel_size= (3, 3), activation= 'relu')) #  convolution layer\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size= (2, 2))) # pooling layer\n",
    "\n",
    "model.add(Flatten()) # flatten layer\n",
    "\n",
    "model.add(Dense(units= 128, activation= 'relu')) # hidden layer\n",
    "model.add(Dropout(rate= 0.2))\n",
    "\n",
    "model.add(Dense(units= 128, activation= 'relu')) # hidden layer\n",
    "model.add(Dropout(rate= 0.2))\n",
    "\n",
    "model.add(Dense(units= 10, activation= 'softmax')) # output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">102,528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m102,528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">130,154</span> (508.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m130,154\u001b[0m (508.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">130,026</span> (507.91 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m130,026\u001b[0m (507.91 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> (512.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m128\u001b[0m (512.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss= 'categorical_crossentropy', optimizer= tf.keras.optimizers.Adam(), metrics= ['accuracy', ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 42ms/step - accuracy: 0.8630 - loss: 0.4416 - val_accuracy: 0.9673 - val_loss: 0.1201\n",
      "Epoch 2/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 40ms/step - accuracy: 0.9802 - loss: 0.0659 - val_accuracy: 0.9848 - val_loss: 0.0502\n",
      "Epoch 3/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 37ms/step - accuracy: 0.9857 - loss: 0.0478 - val_accuracy: 0.9893 - val_loss: 0.0348\n",
      "Epoch 4/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 32ms/step - accuracy: 0.9899 - loss: 0.0349 - val_accuracy: 0.9902 - val_loss: 0.0340\n",
      "Epoch 5/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 31ms/step - accuracy: 0.9906 - loss: 0.0292 - val_accuracy: 0.9909 - val_loss: 0.0333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2436d4928d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs= 5,\n",
    "    batch_size= 128,\n",
    "    validation_data = (x_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9887 - loss: 0.0413\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03333578631281853, 0.9908999800682068]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
